
export interface ProjectImage {
  src: string;
  alt: string;
  caption?: string;
}

export interface Project {
  id: string;
  title: string;
  category: 'AI' | 'Robotics' | 'Research';
  metric?: string;
  description: string;
  longDescription?: string;
  tech: string[];
  image: string;
  gallery?: ProjectImage[];
  color: string;
  featured: boolean;
  link?: string;
  github?: string;
  documentation?: string;
  year?: string;
  role?: string;
  architectureImage?: string;
}

export const projects: Project[] = [
  // ==================== AI PROJECTS ====================
  {
    id: 'news-researcher',
    title: 'News Researcher AI Agents',
    category: 'AI',
    metric: 'Multi-Agent System',
    description: 'Autonomous multi-agent system for researching and synthesizing news using LLMs to aggregate and analyze current events.',
    longDescription: 'Designed and implemented a sophisticated multi-agent system where specialized AI agents collaborate to research news topics. The system employs a "Manager" agent to delegate tasks to "Researcher" and "Writer" agents. It leverages LangChain and OpenAI GPT-4 to scrape web content, verify facts, and generate comprehensive reports. CrewAI framework generating 40+ articles daily with 85% accuracy.',
    tech: ['LangChain', 'OpenAI GPT-4', 'Python', 'Streamlit', 'Serper API'],
    image: '/images/projects/arch_news_1.png',
    architectureImage: '/images/projects/arch_news_researcher.png',
    gallery: [
      { src: '/images/projects/arch_news_researcher.png', alt: 'System Architecture', caption: 'Full system design' }
    ],
    color: '#3B82F6',
    featured: true,
    year: '2024',
    role: 'AI Engineer',
    github: 'https://github.com/srujan29112001',
    link: 'https://drive.google.com/file/d/1LoNq_7YDIDbSJ2BDyVCWGmynYpG1KhDB/view?usp=drive_link'
  },
  {
    id: 'neuropsych-trading',
    title: 'NeuroPsych Trading Assistant',
    category: 'AI',
    metric: 'Neuromorphic BCI',
    description: 'Neuromorphic multi-agent system combining Brain-Computer Interface (BCI) with computational psychiatry for trading.',
    longDescription: 'The NeuroPsych Trading Assistant represents a groundbreaking convergence of neuromorphic computing, computational psychiatry, robotics, and electronic systems design to address the critical mental health crisis among retail traders. This project develops a comprehensive ecosystem that monitors, predicts, and intervenes in real-time to prevent emotion-driven trading losses and mental health deterioration. My system employs cutting-edge neuromorphic hardware design, EEG-based brain-computer interfaces, computer vision, multi-agent AI coordination, and robotic companions to create the world\'s first comprehensive mental health support system for high-stress financial decision-making.',
    tech: ['BCI', 'EEG Processing', 'Multi-Agent Systems', 'Python', 'Neuromorphic Computing'],
    image: '/images/projects/neuropsych-trading.png',
    architectureImage: '/images/projects/arch_neuropsych_trading.png',
    gallery: [
      { src: '/images/projects/arch_neuropsych_trading.png', alt: 'System Architecture', caption: 'Neuromorphic design' }
    ],
    color: '#10B981',
    featured: true,
    year: '2024',
    role: 'Lead Researcher',
    link: 'https://srujan29112001.github.io/AI-SRUJAN/'
  },
  {
    id: 'wellness-ai',
    title: 'Personalized Wellness AI for Holistic Health',
    category: 'AI',
    metric: 'MCP & A2A Agents',
    description: 'Interconnected mind-body-spirit wellness system using collaborative AI agents and MCP protocol.',
    longDescription: 'An AI-powered holistic wellness platform that analyzes EEG brain signals, provides conversational AI coaching, and delivers personalized health recommendations by integrating traditional Ayurvedic wisdom with modern nutritional science. The platform combines multi-modal health data processing (brainwaves, voice emotion, food recognition) with advanced ML models and knowledge graphs.',
    tech: ['Wellness AI', 'Ayurveda', 'EEG Analysis', 'GraphRAG', 'Voice Emotion Detection'],
    image: '/images/projects/arch_wellness_1.png',
    gallery: [], // Empty gallery to prevent duplicate single image in carousel
    color: '#06B6D4',
    featured: true,
    year: '2024',
    role: 'Full Stack AI Developer',
    github: 'https://github.com/Srujan29112001/Holistic-Wellness-app',
    link: 'https://srujan29112001.github.io/AI-SRUJAN/'
  },
  {
    id: 'clinical-ai-copilot',
    title: 'Clinical AI Copilot with Multimodal EEG + Clinical RAG',
    category: 'AI',
    metric: 'Medical RAG',
    description: 'Enterprise-grade healthcare AI system combining real-time EEG signal analysis with clinical knowledge retrieval.',
    longDescription: 'Conversational AI for neurological disorder detection providing accurate diagnosis and treatment recommendations. Combines multimodal deep learning models (CNN-LSTM, Transformer, SNN) for real-time EEG analysis with GraphRAG-powered medical knowledge bases. Fully HIPAA compliant architecture using FastAPI, Neo4j, and Kafka.',
    tech: ['EEG Signal Processing', 'GraphRAG', 'Multimodal AI', 'BioBERT', 'Spiking Neural Networks'],
    image: '/images/projects/clinical-ai.png',
    gallery: [], // Prevent duplicate
    color: '#EC4899',
    featured: true,
    year: '2024',
    role: 'Lead AI Engineer',
    link: '#'
  },
  {
    id: 'advisory-platform',
    title: 'Entrepreneurship Intelligence Platform (EIP)',
    category: 'AI',
    metric: 'Enterprise GraphRAG',
    description: 'Enterprise-grade AI platform featuring 35 specialized agents for comprehensive business intelligence.',
    longDescription: 'An enterprise-grade AI platform featuring 35 specialized agents (Policy, Market, Finance, Legal, HR, ESG, etc.) with GraphRAG knowledge systems. Delivers multi-agent collaboration and comprehensive business intelligence for entrepreneurs, covering tax optimization, investment analysis, and competitive intelligence.',
    tech: ['GraphRAG', 'Multi-Agent System', 'Vector Database', 'Knowledge Graph', 'FastAPI'],
    image: '/images/projects/arch_advisory_1.png',
    gallery: [], // Prevent duplicate
    color: '#6D64A3',
    featured: true,
    year: '2024',
    role: 'AI Architect',
    github: 'https://github.com/Srujan29112001/Entra',
    link: 'https://srujan29112001.github.io/AI-SRUJAN/'
  },
  {
    id: 'finance-copilot',
    title: 'Finance Analytics & Trading Co-Pilot',
    category: 'AI',
    metric: 'Real-Time Streaming',
    description: 'Real-time platform combining Apache Kafka/Spark streaming with AI-powered trading insights.',
    longDescription: 'A highly scalable finance analytics platform fusing multi-modal data (market prices, news sentiment, social signals) to drive reinforcement learning trading agents (DQN). Features a LangChain RAG copilot for interactive financial insights and real-time observability via Prometheus/Grafana.',
    tech: ['Apache Kafka', 'Spark', 'Reinforcement Learning', 'LangChain', 'DQN', 'Microservices'],
    image: '/images/projects/arch_finance_copilot.png',
    gallery: [], // Prevent duplicate
    color: '#22C55E',
    featured: true,
    year: '2024',
    role: 'Lead Architect',
    link: '#'
  },
  {
    id: 'vehicle-tracking',
    title: 'Speed Estimation and Vehicle Tracking System',
    category: 'AI',
    metric: 'YOLOv8',
    description: 'Automated vehicle detection, tracking, and speed calculation using YOLOv8 and computer vision.',
    longDescription: 'Traditional traffic monitoring systems lack accuracy in real-time speed estimation. This project addresses these gaps by automating vehicle detection, tracking, and speed calculation using YOLOv8. Key features include custom tracking algorithm and speed calculation as vehicles cross predefined lines.',
    tech: ['YOLOv8', 'Computer Vision', 'Deep Learning', 'Python'],
    image: '/images/projects/vehicle-tracking.png',
    color: '#EF4444',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1UqPIOl2oD8quSNWniIEDeH8kXOGdK_BF/view?usp=sharing',
    link: 'https://drive.google.com/file/d/17JO_k02YTMQoumhm95J3EA6V3N7fUMIE/view?usp=drive_link'
  },
  {
    id: 'alphafold',
    title: '3D Protein Structure Prediction Using AlphaFold',
    category: 'AI',
    metric: 'AlphaFold',
    description: 'Predicting high-accuracy 3D protein structures from amino acid sequences using AlphaFold.',
    longDescription: 'This project leverages AlphaFold\'s deep learning framework to predict high-accuracy 3D protein structures from amino acid sequences. The workflow includes environment setup in Google Colab, dependency installation (JAX, OpenMM), genetic database searches (UniRef90, smallBFD) for MSA generation via Jackhmmer, and structure prediction using monomer/multimer models. Results achieved sub-ångström RMSD accuracy in structural relaxation, with confidence scores (pLDDT) exceeding 90% for core regions. Predicted PDB files and interactive 3D visualizations (py3Dmol) are generated, enabling rapid insights for drug discovery and functional analysis. The end-to-end pipeline demonstrates 85%+ computational efficiency in Colab, bridging the gap between sequence data and structural biology applications.',
    tech: ['AlphaFold', 'Deep Learning', 'Bioinformatics', 'Python'],
    image: '/images/projects/alphafold.png',
    color: '#8B5CF6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1-tHGikDQ0KsKPzh1gkqWQimGbgzbCwzo/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1UXka9_8ueddFWr2_LIjX3dsi6l4Sc0aJ/view?usp=drive_link'
  },
  {
    id: 'simulation-evolution',
    title: 'Simulation Of Evolution',
    category: 'AI',
    metric: 'Genetic Algorithm',
    description: 'Simulating evolutionary principles using a genetic algorithm to optimize image populations.',
    longDescription: 'This project simulates evolutionary principles using a genetic algorithm to optimize a population of randomly generated images toward a target color. By iteratively selecting top-performing "elite" images, blending their RGB values through crossover, and introducing controlled mutations, the algorithm reduces the mean absolute RGB difference (fitness score) across generations. Over 50–100 generations, the system achieved a 95%+ reduction in fitness scores, converging to within 5 RGB units of the target color. The solution was extended to evolve 16x16 pixel grids, demonstrating scalability. Key metrics include mutation rate optimization (0.1–5%), elite retention (10–20%), and fitness-driven convergence.',
    tech: ['Genetic Algorithms', 'Python', 'Simulation', 'Optimization'],
    image: '/images/projects/evolutionary-sim.png',
    color: '#10B981',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1yle4uFPpablrbNbh2vu_CeEELpXErxdH/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1vqF9JT7hqPYHwKPKEGwvOQF9Nl8c42nI/view?usp=drive_link'
  },
  {
    id: 'word-similarity',
    title: 'Word Similarity Predictor',
    category: 'AI',
    metric: 'Word2Vec',
    description: 'Analyzing semantic relationships in product reviews using Word2Vec and Gensim.',
    longDescription: 'This project involves the application of Word2Vec to a dataset of product reviews. The goal is to train a Word2Vec model on the review texts of cell phones and accessories and analyze semantic relationships between different words.',
    tech: ['NLP', 'Word2Vec', 'Gensim', 'Python'],
    image: '/images/projects/arch_word_1.png',
    color: '#6366F1',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1fnfMxCc-lXLICGKQ2ogI6jxUqxcocs4R/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1g2h1Doo8riJtBG4uEnmw9sHlN7gMsN5s/view?usp=drive_link'
  },
  {
    id: 'stock-rl',
    title: 'Stock Trading Reinforcement Learning',
    category: 'AI',
    metric: 'Reinforcement Learning',
    description: 'Developing reinforcement learning models that autonomously learn and evolve trading strategies.',
    longDescription: 'Traditional algorithmic trading strategies struggle to adapt to dynamic market regimes. This project addresses this gap by developing reinforcement learning models that autonomously learn and evolve strategies from historical data, optimizing for risk-adjusted returns in unpredictable financial environments.',
    tech: ['Reinforcement Learning', 'Finance AI', 'Python'],
    image: '/images/projects/arch_stock_1.png',
    color: '#22C55E',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1j_j4wVkOCFekHzcBHUX7szmujDygMjxs/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1WYAxpO8CgN8S7f8tXoYzijDIbpI1ai9A/view?usp=drive_link'
  },
  {
    id: 'ludo-q-learning',
    title: 'Optimized Ludo with Q-Learning',
    category: 'AI',
    metric: 'Q-Learning',
    description: 'Autonomous Ludo agent that learns optimal moves through trial and error using Q-learning.',
    longDescription: 'Traditional rule-based Ludo AI lacks adaptability. This project addresses the need for an autonomous agent that learns optimal moves through trial and error, using Q-learning to balance short-term rewards and long-term winning strategies.',
    tech: ['Q-Learning', 'Reinforcement Learning', 'Game AI', 'Python'],
    image: '/images/projects/arch_ludo_1.png',
    color: '#F43F5E',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1jW5VVQMPeUcjiy11K6qEXb1s6uAtoN0p/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1pWOdf7ibGoySDqv3t-BuRXMVapnhgDbf/view?usp=sharing'
  },
  {
    id: 'llama-lora',
    title: 'Fine-Tuning Llama-2-7b With LORA And QLoRA',
    category: 'AI',
    metric: 'LLM Fine-tuning',
    description: 'Efficiently adapting Llama-2-7b using QLoRA for cost-effective customization.',
    longDescription: 'Traditional fine-tuning of large models demands prohibitive resources. This project demonstrates fine-tuning the Llama-2-7b model using QLoRA, a 4-bit quantization method, to optimize memory usage while preserving performance.',
    tech: ['LLM', 'QLoRA', 'LoRA', 'Hugging Face', 'Python'],
    image: '/images/projects/arch_lora_1.png',
    color: '#A855F7',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1ESxkUXoOtJHz7hCWsQNtHl7CCX6dP4p6/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1Q-SIlNpqD-UqUPjqSZOEr-mR3TSVJutm/view?usp=drive_link'
  },
  {
    id: 'rag-llama3',
    title: 'RAG-Powered QA System with LLAMA3',
    category: 'AI',
    metric: 'LLAMA3 RAG',
    description: 'Retrieval-Augmented Generation system using LLAMA3-70B and NVIDIA embeddings for context-aware QA.',
    longDescription: 'Built a Retrieval-Augmented Generation (RAG) system using LLAMA3-70B and NVIDIA embeddings to enable context-aware question answering over custom documents. Solves dynamic information retrieval challenges by combining real-time document processing with LLAMA3\'s reasoning.',
    tech: ['RAG', 'LLAMA3', 'NVIDIA Embeddings', 'LangChain'],
    image: '/images/projects/arch_rag3_1.png',
    color: '#3B82F6',
    featured: false,
    year: '2024',
    documentation: 'https://drive.google.com/file/d/1SbpRzNaI3rhNNpZgbnM-3AuH3YeDl0DD/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1OMwJPxw0sAJad32p-R23BRQ5ON2dFpIw/view?usp=drive_link'
  },
  {
    id: 'rag-gemma',
    title: 'RAG On Gemma',
    category: 'AI',
    metric: 'Gemma Groq',
    description: 'RAG system using GEMMA GROQ and Langchain for document ingestion and QA.',
    longDescription: 'This project focuses on building a RAG system using GEMMA GROQ and various Langchain components. The system ingests documents, processes them into vector embeddings using FAISS, and allows users to query them via a Streamlit interface.',
    tech: ['RAG', 'Gemma', 'Groq', 'LangChain', 'Streamlit'],
    image: '/images/projects/arch_gemma_1.png',
    color: '#0EA5E9',
    featured: false,
    year: '2024',
    documentation: 'https://drive.google.com/file/d/17gXGpI1MiXpxVuuaQ7AU95V4mSus2zgM/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1nRpZqcww_5J2E0vwRG7MjD9hKdLWvU2C/view?usp=drive_link'
  },
  {
    id: 'yelp-sentiment',
    title: 'Sentiment Analysis Of Yelp Reviews',
    category: 'AI',
    metric: 'BERT',
    description: 'Automated sentiment classification of customer reviews using BERT to deliver scalable, objective insights.',
    longDescription: 'Manual analysis of vast customer reviews is time-intensive and prone to subjective bias. This project addresses the challenge by automating sentiment classification using BERT to deliver scalable, objective insights from Yelp reviews. Automates sentiment classification using web scraping and a pre-trained BERT model.',
    tech: ['BERT', 'NLP', 'Web Scraping', 'Python'],
    image: '/images/projects/arch_yelp_1.png',
    color: '#FF0000',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1f5u8kNpKuST7mS8bmceZV85zKKp1-lK6/view?usp=sharing',
    link: 'https://drive.google.com/file/d/18cbSHKHJbbqiCqbQQEIARR13Lnhzw_we/view?usp=drive_link'
  },
  {
    id: 'imdb-sentiment',
    title: 'IMDB Sentiment Analysis',
    category: 'AI',
    metric: 'SNN/CNN/LSTM',
    description: 'Evaluating SNN, CNN, and LSTM models for sentiment analysis on IMDb movie reviews using GloVe embeddings.',
    longDescription: 'Involves preprocessing text data, creating word embeddings using GloVe, and training three types of neural networks: SNN, CNN, and LSTM. The best-performing model is used to predict sentiments on unseen movie reviews.',
    tech: ['Deep Learning', 'LSTM', 'CNN', 'NLP', 'GloVe'],
    image: '/images/projects/arch_imdb_1.png',
    color: '#F5C518',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1iiMt5LO6vCEqcYfATWiucDp11KCYKwG7/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1Bvf8isfa5dm9CDU2I8iW8Rn3uF1BWV89/view?usp=drive_link'
  },
  {
    id: 'brain-tumor',
    title: 'Brain Tumor Classification',
    category: 'AI',
    metric: 'MRI Analysis',
    description: 'Automated classification system for brain tumors in MRI images using machine learning.',
    longDescription: 'This project demonstrates the development of a machine learning system to classify brain tumors in MRI images into "no tumor" and "pituitary tumor" categories. It involves preprocessing MRI scans (resizing, grayscale conversion, normalization) and training Logistic Regression and SVM models. The system achieved 97.14% accuracy with Logistic Regression and 95.51% with SVM, validated on a test dataset. Misclassification analysis highlighted robustness, with only 38 mislabeled samples out of 879. The final implementation includes a user-friendly interface for rapid tumor detection, emphasizing its potential to assist medical diagnostics.',
    tech: ['Machine Learning', 'Medical Imaging', 'SVM', 'Python'],
    image: '/images/projects/arch_tumor_1.png',
    color: '#8B5CF6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1K9G82896KDNmSb-b9LTMVGbUqitO9RGn/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1YoqHn6t47-JhjPT62kx42AUDcwteT9yP/view?usp=drive_link'
  },
  {
    id: 'breast-cancer',
    title: 'Breast Cancer Tumor Classification',
    category: 'AI',
    metric: 'SVM Classifier',
    description: 'Classification of breast cancer tumors into malignant or benign categories using SVM.',
    longDescription: 'This project aims to classify breast cancer tumors into malignant or benign categories using machine learning techniques. The dataset is preprocessed by handling missing values and encoding categorical features. An SVM model is then trained and evaluated using cross-validation to ensure robust performance. A pipeline is implemented to integrate data scaling and model training, ensuring that the preprocessing steps are consistently applied during evaluation.',
    tech: ['SVM', 'Machine Learning', 'Healthcare AI', 'Python'],
    image: '/images/projects/arch_cancer_1.png',
    color: '#EC4899',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1eke8C7hTGTRWQrOC76ennX91vkL9iu99/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1AlxcSE_pu4hJEVW2Wb_-V2uYNfIBqfCI/view?usp=drive_link'
  },
  {
    id: 'esrgan',
    title: 'ESRGAN Super Resolution',
    category: 'AI',
    metric: 'Generative AI',
    description: 'Implementation of ESRGAN to enhance image resolution using deep learning-based super-resolution.',
    longDescription: 'Involves running the ESRGAN model to enhance the resolution of images. ESRGAN is a state-of-the-art method in the field of image super-resolution, utilizing a deep learning-based approach.',
    tech: ['ESRGAN', 'PyTorch', 'GANs', 'Computer Vision'],
    image: '/images/projects/arch_esrgan_1.png',
    color: '#3B82F6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1hiYgZbDpwv2gk2T1bDi_MnIrpC-FWH5s/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/14BeY2Drf4DBNdAvrwNtJfKJopGRlKVtj/view?usp=drive_link'
  },
  {
    id: 'neuron-segmentation',
    title: 'Neuron Segmentation',
    category: 'AI',
    metric: 'Segment Anything',
    description: 'Automated neuron segmentation in microscopy images using Meta\'s Segment Anything Model (SAM).',
    longDescription: 'This project leverages Meta\'s Segment Anything Model (SAM) to automate neuron segmentation in microscopy images, accelerating neurobiological analysis. Using PyTorch and GPU acceleration (NVIDIA RTX 3060), SAM generates precise segmentation masks with a 0.92 mean IoU (Intersection over Union) and processes images 40% faster than manual annotation. The model adapts to diverse neuron morphologies via customizable parameters like pred_iou_thresh=0.9 and min_mask_region_area=100, validated through quantitative metrics and visual inspection. The solution demonstrates SAM\'s versatility for biomedical imaging tasks while maintaining computational efficiency for scalable research applications.',
    tech: ['SAM', 'PyTorch', 'Medical Imaging', 'Computer Vision'],
    image: '/images/projects/arch_neuron_1.png',
    color: '#10B981',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1ze5J3K5tjZngrjqMeNPiGWKarzt9dXun/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1eyABVrUlExt-apfXNCc_txCqmLYHGzvd/view?usp=drive_link'
  },
  {
    id: 'sandstones',
    title: 'Sandstones Segmentation',
    category: 'AI',
    metric: 'U-Net',
    description: 'U-Net model to segment sandstone images into clay, quartz, and pyrite classes.',
    longDescription: 'This project involves building a U-Net model to segment sandstone images into different classes, such as clay, quartz, and pyrite. The project was executed on Google Colab, leveraging the GPU for faster training. The model was trained using a dataset of 128x128 pixel patches and evaluated on a separate test set. The performance of the model was assessed using accuracy and IoU metrics, achieving a mean IoU of 0.8665 and an accuracy of 96.37%.',
    tech: ['U-Net', 'Deep Learning', 'Geology AI', 'Python'],
    image: '/images/projects/arch_sandstone_1.png',
    color: '#D97706',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/10ZqytMMbCoOed2OlgPeQ9bG03xJDwe4y/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1SPavtnxRNC6XFguXxQ4lUoRz2rogrGSD/view?usp=drive_link'
  },
  {
    id: 'deep-audio',
    title: 'Deep Audio Classifier',
    category: 'AI',
    metric: 'MFCC & CNN',
    description: 'Urban sound classification using MFCC features and neural networks on the UrbanSound8K dataset.',
    longDescription: 'Urban sound recognition is challenging due to overlapping acoustic patterns and environmental noise. This project solves this by developing an MFCC-driven neural network to classify sounds accurately, enabling scalable noise monitoring and urban analytics. Using the UrbanSound8K dataset, the model achieved 85% test accuracy.',
    tech: ['Audio Processing', 'Deep Learning', 'MFCC', 'Python'],
    image: '/images/projects/arch_audio_1.png',
    color: '#6366F1',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1i_SvYd_FbdifHGsw9tb_lLQBHELGXd0K/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1oIB0Jqn38J84iPwhUxTVTIZBqH0AcxYL/view?usp=sharing'
  },
  {
    id: 'lip-read',
    title: 'Lip Read to Text',
    category: 'AI',
    metric: '3D CNN + LSTM',
    description: 'Visual speech recognition model using 3D CNNs and Bidirectional LSTMs to transcribe silent speech.',
    longDescription: 'Existing visual speech recognition systems struggle to accurately transcribe spoken words from lip movements due to variable lighting, speaker differences, and lack of temporal alignment. This project addresses these challenges by developing a deep learning model (3D CNN + Bidirectional LSTM) to automate silent speech interpretation with robust spatiotemporal feature extraction and CTC-based alignment-free training.',
    tech: ['3D CNN', 'LSTM', 'TensorFlow', 'Computer Vision'],
    image: '/images/projects/arch_lip_1.png',
    color: '#F43F5E',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1hlZQTdIb1GzAGZbhJ9XJHZWV2KXZJgs8/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1ps7LjiKgnh4-PDLa24N6IDAv0J81clgl/view?usp=drive_link'
  },
  {
    id: 'image-to-3d',
    title: '2D Image to 3D Point Cloud',
    category: 'AI',
    metric: 'Depth Estimation',
    description: 'Reconstructing 3D meshes from 2D images using depth estimation transformers and Open3D.',
    longDescription: 'Uses a depth estimation model from Hugging Face Transformers to predict depth from a 2D image. The depth map is used to create a point cloud, which is processed to reconstruct a 3D mesh using Open3D.',
    tech: ['Transformers', 'Open3D', 'Computer Vision', 'Python'],
    image: '/images/projects/arch_3d_1.png',
    color: '#0EA5E9',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1RBcmLM5-aizNkmyKtjJXM6qsc24FI_8f/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1qeGzIMvqmcuScaa15FPmolMsjsgynWNw/view?usp=sharing'
  },
  {
    id: 'pointnet',
    title: 'PointNet Classification',
    category: 'AI',
    metric: '3D Deep Learning',
    description: '3D shape classification system using TensorFlow and PointNet architecture on ModelNet10 dataset.',
    longDescription: 'Creates a 3D shape classification system using TensorFlow and the PointNet architecture. The ModelNet10 dataset is used, consisting of 3D object files. Includes data preprocessing, model building, and evaluation.',
    tech: ['PointNet', 'TensorFlow', '3D Vision', 'Python'],
    image: '/images/projects/pointnet.png',
    color: '#8B5CF6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1E_nkeD5kHpWI5VSPh295BF7qWroe7xem/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1KqVAM8r2UCOewm-tRPP79fMXtdxDOEwN/view?usp=drive_link'
  },
  {
    id: 'midas-depth',
    title: 'Real-Time Depth Estimation',
    category: 'AI',
    metric: 'MiDaS',
    description: 'Real-time monocular depth estimation using MiDaS models to infer 3D structure from 2D webcam input.',
    longDescription: 'Traditional depth sensing relies on specialized hardware (e.g., LiDAR, stereo cameras), which is costly and computationally intensive. This project addresses this gap by implementing a real-time, GPU-accelerated monocular depth estimation system using lightweight MiDaS models to democratize 3D perception from standard 2D webcams. Processes 20-30 FPS with optimized inference.',
    tech: ['MiDaS', 'PyTorch', 'Computer Vision', 'Real-time'],
    image: '/images/projects/midas-depth.png',
    color: '#14B8A6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1for27_u2Bv3fheU_Av9ljfehQFm_cS03/view?usp=sharing',
    link: 'https://drive.google.com/file/d/17FdFmYfIyzBCxLE3S3qUmYa851rBLtkf/view?usp=drive_link'
  },
  {
    id: 'weather-prophet',
    title: 'Weather Prediction',
    category: 'AI',
    metric: 'NeuralProphet',
    description: 'Forecasting temperature trends using NeuralProphet, a hybrid time-series model.',
    longDescription: 'Rising climate variability in Williamtown demands accurate temperature forecasts to mitigate risks for agriculture and infrastructure. This project addresses the gap in localized, long-term predictions by leveraging NeuralProphet to model historical weather patterns and generate actionable forecasts. Forecasts temperature trends using NeuralProphet, a hybrid time-series model.',
    tech: ['NeuralProphet', 'Time Series', 'Python', 'Data Science'],
    image: '/images/projects/weather-pred.png',
    color: '#F59E0B',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1oPgMMp-RmQ0JqHJIn8b3l34P55cKQP5m/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1PYoDuCL8rZ_8KghvN7aFlZS8114Be_Fh/view?usp=drive_link'
  },
  {
    id: 'sales-arima',
    title: 'Sales Forecasting',
    category: 'AI',
    metric: 'ARIMA/SARIMAX',
    description: 'Monthly sales forecasting using statistical time series analysis techniques.',
    longDescription: 'Analyzes a monthly sales dataset to forecast future sales using ARIMA and SARIMAX models. Data is preprocessed, models are fitted, and forecasts specific to time periods are generated.',
    tech: ['ARIMA', 'Statistics', 'Time Series', 'Python'],
    image: '/images/projects/sales-forecasting.png',
    color: '#22C55E',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1v7jX3pgUazcWWkhZTxtD72IZVf2PLK-I/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1bpkR3dSO7ezBeisGPcvImCajTWMtdvMo/view?usp=drive_link'
  },
  {
    id: 'census-gpu',
    title: 'GPU-Accelerated Census Analysis',
    category: 'AI',
    metric: 'RAPIDS cuML',
    description: 'Optimizing U.S. Census data analysis using NVIDIA RAPIDS for GPU-accelerated machine learning.',
    longDescription: 'Solves computational bottlenecks in processing large datasets by implementing GPU-accelerated preprocessing with RAPIDS. Systematically compares ML models to identify the optimal approach for income prediction.',
    tech: ['RAPIDS', 'cuML', 'GPU Computing', 'Data Science'],
    image: '/images/projects/census-gpu.png',
    color: '#76B900',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1GSohsE8NSQF_uYoN0VqR4O7LrpseFH4_/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1zOE7hMQKqYgffmQwg7LnFdi2lxOn2pCE/view?usp=drive_link'
  },
  {
    id: 'steel-pso',
    title: 'Steel Strength Optimization',
    category: 'AI',
    metric: 'PSO + Random Forest',
    description: 'Predicting steel yield strength using Random Forest optimized with Particle Swarm Optimization.',
    longDescription: 'Predicts yield strength of steel using Random Forest Regressor optimized with Particle Swarm Optimization (PSO). PSO is implemented to find the optimal set of features that maximize yield strength.',
    tech: ['PSO', 'Random Forest', 'Optimization', 'Python'],
    image: '/images/projects/steel-optimization.png',
    color: '#64748B',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1BBethH-CFCfgbV5JosAT0OIFUI8aZoe3/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1Eq9p5surHhfGO9ZOM6Rt4Qu8kX_lP9KN/view?usp=sharing'
  },
  {
    id: 'rps-fastervit',
    title: 'RPS Gesture Classifier',
    category: 'AI',
    metric: 'FasterViT',
    description: 'Real-time Rock-Paper-Scissors gesture classifier using FasterViT for sub-20ms inference.',
    longDescription: 'Addresses the gap in real-time gesture classification by implementing FasterViT, a vision transformer optimized for efficiency. Achieves sub-20ms inference times with >98% accuracy.',
    tech: ['FasterViT', 'Transformers', 'Computer Vision', 'Real-time'],
    image: '/images/projects/rps-gesture.png',
    color: '#F97316',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1oK2qijwqPXxs7Ouj1AgiSHY8u-6SkZ2K/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1bthm5ogWYgUVfjlpMgUkK1DlgV1dz90E/view?usp=drive_link'
  },
  {
    id: 'daisy-dandelion',
    title: 'Daisy vs Dandelion',
    category: 'AI',
    metric: 'Swin Transformer',
    description: 'Image classifier using Swin Transformer to differentiate between flower species.',
    longDescription: 'Leverages the Swin Transformer to differentiate between daisies and dandelions. Implemented using Jupyter Lab with GPU support.',
    tech: ['Swin Transformer', 'Computer Vision', 'Deep Learning'],
    image: '/images/projects/flower-class.png',
    color: '#EAB308',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1nBUxmpCyBpMzLU0tK3xnk0EcXZNKEuYt/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1LZLDfW4caMM5iZhtnzs0be2uwlFv768i/view?usp=drive_link'
  },
  {
    id: 'happy-sad',
    title: 'Happy or Sad Classifier',
    category: 'AI',
    metric: 'CNN',
    description: 'Simple CNN model to classify images of faces as happy or sad.',
    longDescription: 'Involves preprocessing image data, creating a CNN model, training it, and evaluating its performance in classifying images into two emotional categories.',
    tech: ['CNN', 'Deep Learning', 'Computer Vision'],
    image: '/images/projects/emotion-class.png',
    color: '#8B5CF6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1pttNmzVRI8iq0rxXllxRMTjPgWLf9hW-/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1_8_8PJrHWsArQF4q1NYTwgYCmY56tv1Q/view?usp=drive_link'
  },
  // ==================== ROBOTICS PROJECTS ====================
  {
    id: 'robovla',
    title: 'Vision-Language Robotic Assistant (VLA-Sim)',
    category: 'Robotics',
    metric: 'Embodied VLA',
    description: 'Embodied AI system integrating vision-language models with ROS2 for autonomous service tasks.',
    longDescription: 'RoboVLA is a production-grade AI system for robotic warehouse automation that integrates computer vision (DINO v2, MiDaS, 3D Gaussian Splatting), natural language understanding (Llama 3.1, CLIP), and knowledge graphs (Neo4j, ChromaDB) to enable robots to understand commands and execute pick-and-place tasks. Optimized for NVIDIA RTX 3060 (12GB VRAM) with INT8/4-bit quantization, featuring FastAPI server, Kubernetes deployment, and Prometheus monitoring for production environments.',
    tech: ['DINO v2', 'Llama 3.1', 'Neo4j', 'Robotics', 'NVIDIA Isaac'],
    image: '/images/projects/robovla.png',
    architectureImage: '/images/projects/arch_robovla.png',
    gallery: [
      { src: '/images/projects/arch_robovla.png', alt: 'Architecture', caption: 'System diagram' }
    ],
    color: '#10B981',
    featured: true,
    year: '2024',
    github: 'https://github.com/Srujan29112001/ROBOWAREHOUSE',
    link: 'https://srujan29112001.github.io/ROBOTICS-SRUJAN/'
  },
  {
    id: 'internship-semester',
    title: 'Internship Semester (UG Final Semester) Project',
    category: 'Robotics',
    metric: 'Edge AI Drone',
    description: 'Real-time aerial object detection system using YOLOv7 on NVIDIA Jetson AGX Xavier.',
    longDescription: 'Aerial vehicles struggle with real-time, low-latency object detection due to small object sizes, computational constraints, and dynamic environments. This project addresses the gap by deploying an edge-optimized YOLOv7 model to enable accurate, real-time detection on drones without cloud dependency. Developed a real-time aerial object detection system using YOLOv7, trained on a custom dataset with NVIDIA Jetson AGX Xavier. Deployed on the "Tunga" aerial vehicle (NVIDIA Jetson Nano + Pixhawk) to enable edge-computing for dynamic environments. Achieved 89% mAP, 22 FPS inference speed, and 95% reliability.',
    tech: ['YOLOv7', 'NVIDIA Jetson', 'Edge AI', 'Computer Vision'],
    image: '/images/projects/drdo-aerial.png',
    architectureImage: '/images/projects/arch_drdo_aerial.png',
    color: '#F59E0B',
    featured: false,
    year: '2024',
    documentation: 'https://drive.google.com/drive/folders/1M_hsP4ME88xmN1Oz7PHSEsQ62SkkizNB?usp=sharing',
    link: 'https://drive.google.com/drive/folders/1M_hsP4ME88xmN1Oz7PHSEsQ62SkkizNB?usp=sharing'
  },
  {
    id: 'neural-signal-time-freq',
    title: 'Time-Frequency Analysis of Neural Signals',
    category: 'Robotics',
    metric: 'Signal Processing',
    description: 'Analysis of neural signals using complex Morlet wavelets for high-precision decomposition.',
    longDescription: 'Addressed limitations in EEG signal analysis by implementing complex Morlet wavelets to enable high-precision time-frequency decomposition. Compared with traditional filter-Hilbert methods for robust neural oscillation characterization.',
    tech: ['Siganl Processing', 'EEG', 'Wavelets', 'MATLAB'],
    image: '/images/projects/neural-signal.png',
    color: '#6366F1',
    featured: false,
    year: '2024',
    documentation: 'https://drive.google.com/file/d/174WFLUAsCsRvJn0yrFD4Ug1JxBK4-rUd/view?usp=sharing',
    link: 'https://drive.google.com/file/d/10AdoVKTc1SNIIjdsGTemVcC9ohpVOiEC/view?usp=drive_link'
  },
  {
    id: 'phase-sync',
    title: 'Phase Synchronization Analysis using EEG Data',
    category: 'Robotics',
    metric: 'EEG Analysis',
    description: 'Analysis of phase synchronization between EEG signals using Morlet wavelet transform.',
    longDescription: 'Involves the analysis of phase synchronization between EEG signals from different channels. Using Matlab, computed and visualized phase synchronization using techniques like Morlet wavelet transform, ISPC, and PLI.',
    tech: ['EEG', 'MATLAB', 'Neuroscience', 'Signal Processing'],
    image: '/images/projects/arch_phase_1.png',
    color: '#8B5CF6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1ij23QD0AeQ-zL_pBJZtAydPK69dc0DBV/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/11mkQBTWKCoTjy2iuQPSDM8wPFryCgZWz/view?usp=drive_link'
  },
  {
    id: 'neural-signal-spectral',
    title: 'Neural Signal Spectral Analysis',
    category: 'Robotics',
    metric: 'FFT Analysis',
    description: 'Generating sine waves and analyzing their spectral properties using FFT.',
    longDescription: 'Involves generating sine waves and analyzing their spectral properties using FFT. Includes power spectrum computation, noise impact analysis, and manual Fourier Transform implementation.',
    tech: ['FFT', 'Spectral Analysis', 'Signal Processing', 'MATLAB'],
    image: '/images/projects/neural-spectral.png',
    color: '#F43F5E',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1z8naadsLcCtv7WQhO-Fi-9AmbdZTDXyB/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/15RIx7UBf5djT8ao-p5j3E801gC6QxmME/view?usp=drive_link'
  },
  {
    id: 'simulating-eeg',
    title: 'Simulating EEG Data in MATLAB',
    category: 'Robotics',
    metric: 'Simulation',
    description: 'Simulating EEG data at the dipole level and projecting onto scalp electrodes.',
    longDescription: 'Simulates EEG data at the dipole level using MATLAB. The simulation includes generating pure sine wave signals, adding noise, and creating non-oscillatory and non-stationary signals in dipoles.',
    tech: ['MATLAB', 'Simulation', 'EEG', 'Neuroscience'],
    image: '/images/projects/eeg-sim.png',
    color: '#0EA5E9',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/15hahC4mAdGdYJrxKGk0d7RYtKUDEHuqX/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1ao3f6vngg0dvMw68IndIM0_Ymtr8U5AW/view?usp=drive_link'
  },
  {
    id: 'pathfinding-algo',
    title: 'Comparative Analysis of Pathfinding Algorithms',
    category: 'Robotics',
    metric: 'Algorithms',
    description: 'Comparing BFS, DFS, and A* algorithms for maze navigation efficiency.',
    longDescription: 'Existing pathfinding algorithms vary in efficiency and optimality for maze navigation. This project compares DFS, BFS, and A* to determine their effectiveness in minimizing path length, search time, and heuristic impact on performance. This project implements and evaluates DFS, BFS, and A* algorithms in maze navigation using PyAmaze to visualize pathfinding and measure efficiency. Results show BFS guarantees the shortest path, while A* (with Manhattan heuristic) reduces search time by 25–40% compared to DFS. The Manhattan heuristic outperformed Euclidean in 70% of test cases.',
    tech: ['Python', 'Algorithms', 'Pathfinding', 'Robotics'],
    image: '/images/projects/pathfinding.png',
    color: '#10B981',
    featured: false,
    year: '2023',
    link: 'https://drive.google.com/file/d/1itf6XJKZYSxQQ3GsemLFQl5rt42SJ_v-/view?usp=sharing'
  },
  {
    id: 'lane-changing-control',
    title: 'Autonomous Lane Changing Control System',
    category: 'Robotics',
    metric: 'MPC Control',
    description: 'Model Predictive Control system for autonomous vehicles to execute precise lane-changing.',
    longDescription: 'Designs a Model Predictive Control (MPC) system for autonomous vehicles to execute precise lane-changing maneuvers. The MPC algorithm dynamically optimizes steering inputs over a receding horizon.',
    tech: ['MPC', 'Control Theory', 'MATLAB', 'Autonomous Vehicles'],
    image: '/images/projects/lane-control.png',
    color: '#F97316',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1UpTz5aM6FuVQGSlm-IpGNkot20IL5oMk/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1J8XQ-JZwxC9K85M9zDJRZYnuMkKlu6ys/view?usp=drive_link'
  },
  {
    id: 'water-tank-dynamics',
    title: 'Simulating Water Tank Dynamics',
    category: 'Robotics',
    metric: 'Proportional Control',
    description: 'Simulating dynamics of water volume changes in interconnected tanks with proportional control.',
    longDescription: 'Simulates the dynamics of water volume changes in three interconnected tanks. Employs proportional control to adjust the volume. Visualized using animated plots.',
    tech: ['Control Systems', 'Simulation', 'MATLAB', 'Dynamics'],
    image: '/images/projects/water-tank.png',
    color: '#06B6D4',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1_yZ7eAZA3JJui7N2-CiouHYKhSP3LTTk/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1V3HSZidzz9OtidbneRJhlawvIX9xmXiO/view?usp=drive_link'
  },
  {
    id: 'pid-falling-cube',
    title: 'PID Control Simulation for Falling Cube',
    category: 'Robotics',
    metric: 'PID Control',
    description: 'Simulating a PID-controlled train catching a falling cube.',
    longDescription: 'Simulates a PID-controlled train on an inclined rail trying to catch a falling cube. Calculates displacement, velocity, and PID error metrics. Animated visualization included.',
    tech: ['PID', 'Control Theory', 'MATLAB', 'Simulation'],
    image: '/images/projects/pid-cube.png',
    color: '#EC4899',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1yslDuNLlcBn7WclAAp0edZnZU4FjKRR8/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1av_EO3pLEez9lWdsrHoUO_BzyWDeeYYk/view?usp=drive_link'
  },
  {
    id: 'hand-gesture-cursor',
    title: 'Real Time Hand Gesture Recognition For Cursor Control',
    category: 'Robotics',
    metric: 'MediaPipe',
    description: 'Vision-based system to control cursor movements and clicks through hand gestures.',
    longDescription: 'Traditional input devices limit mobility and accessibility. This project addresses this by designing a vision-based system to control cursor movements and clicks through hand gestures, eliminating physical hardware dependency. Developed a real-time hand gesture recognition system using MediaPipe and PyAutoGUI to enable touchless cursor control. The solution processes webcam input to detect 21 hand landmarks, achieving 95% gesture accuracy, maps finger movements to screen coordinates with less than 50ms latency, and triggers mouse clicks via pinch detection (index-thumb distance <20px).',
    tech: ['Computer Vision', 'MediaPipe', 'HCI', 'Python'],
    image: '/images/projects/gesture-cursor.png',
    color: '#8B5CF6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1jW5VVQMPeUcjiy11K6qEXb1s6uAtoN0p/view?usp=sharing',
    link: 'https://drive.google.com/file/d/18pD_FxZSHZktE_LkAHHy81ZuJzJsY4p7/view?usp=drive_link'
  },
  {
    id: 'pushup-counter',
    title: 'Real Time Pushup Counter',
    category: 'Robotics',
    metric: 'Pose Estimation',
    description: 'Counting push-ups and evaluating form using Mediapipe and OpenCV.',
    longDescription: 'Uses Mediapipe and OpenCV to process video feeds. Counts push-ups from front view and evaluates form from side view by calculating angles between key joints.',
    tech: ['OpenCV', 'MediaPipe', 'Computer Vision', 'Python'],
    image: '/images/projects/pushup-counter.png',
    color: '#10B981',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/18b6hAaXp1-jj_1U3LE4aCUfV3RhNeUMm/view?usp=drive_link',
    link: 'https://drive.google.com/drive/folders/1j7Mjrrfl58mmTMIRsovimnJ03YlmLwhY?usp=drive_link'
  },
  {
    id: 'bicep-curl-counter',
    title: 'Real Time Bicep Curl Counter',
    category: 'Robotics',
    metric: 'Pose Estimation',
    description: 'Real-time bicep curl counting using pose estimation.',
    longDescription: 'Uses Mediapipe pose estimation to analyze video feed. Calculates the angle at the elbow to detect the curl movement and counts repetitions.',
    tech: ['OpenCV', 'MediaPipe', 'Fitness AI', 'Python'],
    image: '/images/projects/bicep-counter.png',
    color: '#F59E0B',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1oskl1rXnQWrQNV7hevUIAbJ3IsAAEz5A/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/11nl8SfuZNa0gtGdKAI_NX9LopomP_yfT/view?usp=drive_link'
  },
  {
    id: 'volume-control',
    title: 'Hand Gesture Volume Control',
    category: 'Robotics',
    metric: 'HCI',
    description: 'Controlling system volume using hand gestures captured via webcam.',
    longDescription: 'Utilizes a webcam to capture hand movements. Measures distance between thumb and index finger to increase or decrease system volume using PyAutoGUI.',
    tech: ['Computer Vision', 'HCI', 'Python', 'MediaPipe'],
    image: '/images/projects/volume-control.png',
    color: '#3B82F6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1sk1imnbX8RNrsVSR9q87AOE1b66XwS3q/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1JeH80W7mR4F7Lvx95AlPjSRUXU551Rwg/view?usp=drive_link'
  },
  {
    id: 'body-pose-react',
    title: 'Real Time Body Pose Estimation',
    category: 'Robotics',
    metric: 'PoseNet',
    description: 'React application for real-time human pose estimation using PoseNet.',
    longDescription: 'React application capturing video from webcam and processing frames with TensorFlow.js PoseNet model to visualize keypoints and skeletons.',
    tech: ['React', 'TensorFlow.js', 'PoseNet', 'Web AI'],
    image: '/images/projects/body-pose.png',
    color: '#8B5CF6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1zzvv007wIwFMBdtGSdUJGJMmeip6rMXB/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/11mXOkEz5jUiIt4XhiGGMih5z-wVZP725/view?usp=drive_link'
  },
  {
    id: 'body-segmentation',
    title: 'Real Time Body Segmentation',
    category: 'Robotics',
    metric: 'BodyPix',
    description: 'Real-time body segmentation using TensorFlow\'s BodyPix model in React.',
    longDescription: 'Demonstrates real-time body segmentation using TensorFlow\'s BodyPix model within a React application. Draws masks of detected body parts on canvas.',
    tech: ['React', 'TensorFlow.js', 'BodyPix', 'Web AI'],
    image: '/images/projects/body-seg.png',
    color: '#EC4899',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1VO4cgljpMC8yJ7fEz8fmzcljD8hyJsvm/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1En8jLjLpjvj-2ivyq0Pn-o11sHnaJ9FU/view?usp=drive_link'
  },
  {
    id: 'hand-pose-react',
    title: 'Real Time Hand Pose Estimation',
    category: 'Robotics',
    metric: 'TensorFlow.js',
    description: 'React application for real-time hand pose detection.',
    longDescription: 'Integrates TensorFlow.js to perform real-time hand pose detection. Renders landmarks on a canvas using the handpose model.',
    tech: ['React', 'TensorFlow.js', 'Handpose', 'Web AI'],
    image: '/images/projects/hand-pose.png',
    color: '#EAB308',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1A_sfzGiag-9r0wkninkuo4AIiGdyB3WQ/view?usp=drive_link',
    link: 'https://drive.google.com/file/d/1eki7QM9JTKEMZ-6iCoeQeGzTyyBdLnew/view?usp=drive_link'
  },
  // ==================== RESEARCH PROJECTS ====================
  {
    id: 'exoplanet-detection',
    title: 'Exoplanet Detection via Light Curves',
    category: 'Research',
    metric: 'Astrophysics',
    description: 'Identifying exoplanets by processing Kepler/TESS mission data using Lightkurve.',
    longDescription: 'This project identifies exoplanets by processing Kepler/TESS mission data using Python\'s Lightkurve library. Light curves of stars are extracted from pixel files, flattened to remove noise, and phase-folded to amplify periodic transit signals. A Box Least Squares (BLS) periodogram pinpoints orbital periods, enabling the detection of a candidate exoplanet with a 5.7-day orbital period, 2-hour transit duration, and 0.1% flux dip—metrics consistent with Earth-sized planets. By automating trend removal and signal validation, the project achieved >95% confidence in transit detection, demonstrating an efficient pipeline for exoplanet candidate screening.',
    tech: ['Python', 'Astrophysics', 'Data Analysis', 'SciPy'],
    image: '/images/projects/exoplanet.png',
    gallery: [],
    color: '#6366F1',
    featured: true,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1KXcRJdTl0CW1dJ_MxOBg3a3t6YhAz9qM/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1LQff1VixZMduQ_hDVV2I9tHSOJWIolez/view?usp=sharing'
  },
  {
    id: 'space-debris',
    title: 'Space Debris Tracking & Collision Prediction',
    category: 'Research',
    metric: 'Physics-Informed NN',
    description: 'Autonomous system for space debris detection, tracking, and collision prediction using YOLOv7 and PINNs.',
    longDescription: 'An enterprise-grade AI system for space situational awareness. Integrates computer vision (YOLOv7, DINO v2) for debris detection with Physics-Informed Neural Networks (PINNs) for precise orbital trajectory prediction. Features real-time 3D dashboard and multi-agent autonomous monitoring.',
    tech: ['YOLOv7', 'PINNs', 'Orbital Mechanics', 'Knowledge Graph', '3D Gaussian Splatting'],
    image: '/images/projects/space-debris.png',
    gallery: [],
    color: '#6366F1',
    featured: true,
    year: '2024',
    role: 'Research Engineer',
    link: '#'
  },
  {
    id: 'quantum-particle',
    title: 'Quantum Particle Detection Dynamics',
    category: 'Research',
    metric: 'Quantum Physics',
    description: 'Analyzing spatiotemporal evolution of a quantum particle wavepacket.',
    longDescription: 'This project analyzes the spatiotemporal evolution of a quantum particle initially localized as a Gaussian wavepacket with zero average momentum. By computing ⟨p²⟩ classically, we derived the arrival time T = mLℏ²/(2a²) (simplified to L² for unit parameters) and contrasted it with quantum dynamics via Fourier expansion and time-dependent Schrödinger solutions. Using SymPy for symbolic derivations and SciPy for numerical integration, we calculated the time-evolving probability P(x>L,t), observing non-zero detection probabilities even at t<T, a hallmark of quantum behavior. Results showed P rising gradually from 0% to ~50% over t=0→30, deviating sharply from the classical prediction of abrupt detection at T. Visualizations highlighted this discrepancy, underscoring quantum tunneling and wavepacket dispersion.',
    tech: ['Quantum Computing', 'Physics Simulation', 'Python', 'NumPy'],
    image: '/images/projects/quantum-dynamics.png',
    color: '#8B5CF6',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/12XYJe34e7WApSzFrnGbV_7lyn9rkIH5S/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1kwQhBWSqk0v61aSamhB1i5ZLjmVYpnu9/view?usp=sharing'
  },
  {
    id: 'lifi-comm',
    title: 'Visible Light Communication System',
    category: 'Research',
    metric: 'LiFi',
    description: 'LiFi based PC to PC communication System (Capstone Project).',
    longDescription: 'Engineering (UG) Group Project (Capstone Project). Traditional RF-based wireless networks face spectrum congestion, security vulnerabilities, and interference issues. This project addresses these limitations by prototyping a LiFi system that leverages visible light for high-bandwidth, low-risk, and energy-efficient PC-to-PC communication. Designed and implemented a LiFi system enabling secure, high-speed data transmission between PCs using modulated LED light and photodetectors. Developed hardware (transceiver circuits) and software (encoding/decoding protocols), achieving a 15 Mbps data rate, less than 10⁻⁵ bit error rate, and 2-meter transmission range.',
    tech: ['LiFi', 'Embedded Systems', 'Communication', 'Hardware'],
    image: '/images/projects/lifi-system.png',
    color: '#F59E0B',
    featured: false,
    documentation: 'https://drive.google.com/file/d/1xaGgViC6ZqSG_RMIFcPvBzCTVtBHB8PN/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1LoNq_7YDIDbSJ2BDyVCWGmynYpG1KhDB/view?usp=drive_link'
  },
  {
    id: 'cellular-automata',
    title: 'Cellular Automata Dynamics Explorer',
    category: 'Research',
    metric: 'Complexity Science',
    description: 'Simulating and visualizing emergent behaviors in 1D/2D cellular automata.',
    longDescription: 'This project simulates and visualizes emergent behaviors in 1D/2D cellular automata using Python, cellpylib, and Matplotlib. By implementing rules like Rule 30, Rule 110, Conway\'s Game of Life, and Totalistic Rule 126, it demonstrates how simple rules generate complex patterns. Custom animations (up to 250 timesteps) reveal phase transitions, self-replication, and chaos. Key outcomes: simulated 4+ rules across 1D/2D models, quantified emergent behaviors (e.g., glider propagation in Game of Life), and interactive visualizations showing rule-dependent evolution. The project bridges theoretical concepts with computational experimentation, highlighting cellular automata\'s role in complexity science and generative systems.',
    tech: ['Cellular Automata', 'Python', 'Simulation', 'Complexity Science'],
    image: '/images/projects/cellular-automata.png',
    color: '#10B981',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1-mWXbkm4SXeZNGVXM8Y2xHCfKallwKqs/view?usp=sharing',
    link: 'https://drive.google.com/file/d/16DRNkKl4_CKk-Bjgc4iUxLL6zG0w_6wp/view?usp=drive_link'
  },
  {
    id: 'covid-simulation',
    title: 'COVID-19 Spread Simulation',
    category: 'Research',
    metric: 'Epidemiology',
    description: 'Simulating COVID-19 spread using SIR models and visualization.',
    longDescription: 'This project simulates the spread of COVID-19 using Python libraries such as Matplotlib and NumPy. The simulation models the infection rate (R0), recovery time, and fatality rate to visualize the progression of the pandemic. The simulation displays the spread of the virus over time, with infected, recovered, and deceased individuals represented on a polar plot. The animation dynamically updates the status of the population, providing a clear depiction of how the virus spreads and the outcomes over time.',
    tech: ['Python', 'Data Visualization', 'Simulation', 'Matplotlib'],
    image: '/images/projects/covid-sim.png',
    color: '#EF4444',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1jkcdypjfS_V1_B_5ve2nBgytGCiawe0U/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1tCXmz6fvERzUJirARFN_-3lsFWgDx530/view?usp=sharing'
  },
  {
    id: 'hilbert-curve',
    title: 'Hilbert Curve Visualization',
    category: 'Research',
    metric: 'Fractals',
    description: 'Interactive visualization of Hilbert curves and their space-filling properties.',
    longDescription: 'This project implements and visualizes Hilbert curves—a type of space-filling fractal curve that maps 1D sequences to 2D space. Using Python\'s Turtle graphics and Tkinter GUI, it constructs recursive Hilbert patterns up to 5th-order iterations (65,536 segments). The implementation showcases algorithmic geometry through precise angle-controlled recursion (90° rotations) and real-time graphical rendering. Key outcomes include interactive visualization of fractal complexity, demonstration of locality preservation (adjacent 1D points map to nearby 2D coordinates), and performance analysis showing exponential growth in curve segments (4^n).',
    tech: ['Fractals', 'Python', 'Tkinter', 'Algorithms'],
    image: '/images/projects/hilbert-curve.png',
    color: '#06B6D4',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1uUzG0yH7lUjmwptDzqy-xSqQnE3Uyqfp/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1XzX7iA6eBHwl-_bLiGYDjKIkjnjUKM7N/view?usp=sharing'
  },
  {
    id: 'barnsley-fern',
    title: 'Barnsley Fern Fractal Generation',
    category: 'Research',
    metric: 'Fractals',
    description: 'Simulating the Barnsley fern using probabilistic affine transformations.',
    longDescription: 'This project leverages Python\'s Turtle graphics to mathematically simulate the Barnsley fern, a naturalistic fractal pattern, using probabilistic affine transformations. By iterating 11,000+ points with four transformation rules (applied at 85% efficiency via optimized rendering), the code replicates the fern\'s intricate self-similar structure with 95% visual accuracy to natural ferns. The implementation demonstrates how algorithmic randomness and deterministic math combine to model organic growth, achieving smooth visualization in VS Code through Turtle\'s performance optimizations (tracer control, instant updates).',
    tech: ['Fractals', 'Python', 'Chaos Theory', 'Math'],
    image: '/images/projects/fractal-gen.png',
    color: '#22C55E',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1HhqQf6UFMEJ4MSgRbcMfbEDyPDsGWbRw/view?usp=sharing',
    link: 'https://drive.google.com/file/d/1EMN91IZDRg-Od8s9YAzi7dACLNhB4c0j/view?usp=sharing'
  },
  {
    id: 'maurer-rose',
    title: 'Maurer Rose Visualization',
    category: 'Research',
    metric: 'Generative Art',
    description: 'Interactive and animated visualization of Maurer roses using p5.js.',
    longDescription: 'This project involves creating an interactive and animated visualization of a Maurer rose using JavaScript and the p5.js library. The Maurer rose is a type of mathematical curve that creates intricate patterns through polar coordinates. The visualization changes dynamically as parameters are adjusted, providing insight into the behavior of the curve.',
    tech: ['p5.js', 'Creative Coding', 'Math', 'JavaScript'],
    image: '/images/projects/maurer-rose.png',
    color: '#EC4899',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1EoSE2njBWId9uASjj_tOohbTrYRrfkm5/view?usp=sharing',
    link: 'https://drive.google.com/file/d/10Z2WIdsP8HDPW4J0Ylcgru8ALUYiDfBH/view?usp=sharing'
  },
  {
    id: 'edge-detection',
    title: 'Edge Detection Algorithms',
    category: 'AI',
    metric: 'Computer Vision',
    description: 'Implementation of Canny edge detection and Gaussian blur for image analysis.',
    longDescription: 'The project involves loading an image, resizing it, converting it to grayscale, applying Gaussian blur, and finally using the Canny edge detection algorithm to identify edges. The results are visualized using Matplotlib, showing the original, resized, grayscale, blurred, and edge-detected images.',
    tech: ['OpenCV', 'Python', 'Image Processing', 'Matplotlib'],
    image: '/images/projects/edge-detection.png',
    color: '#64748B',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1GZqXq9tq4qYq9qXq9qXq9qXq9qXq9qX/view?usp=sharing',
    link: '#'
  },
  {
    id: 'smart-dustbin',
    title: 'Smart Dustbin',
    category: 'Robotics',
    metric: 'Arduino',
    description: 'Automated touchless dustbin using ultrasonic sensors and Arduino UNO.',
    longDescription: 'Manual dustbin lids pose hygiene risks due to frequent contact and often remain open, causing odor and spillage. This project addresses these issues by automating lid operation using sensors, ensuring touchless disposal and timely closure. Designed an Arduino UNO-based smart dustbin with an ultrasonic sensor to enable touchless, hygienic waste disposal. The system detects proximity (up to 50 cm) and opens automatically, reducing physical contact and spillage. Achieved 95% detection accuracy, 0.5-second response time, and 60% improvement in user convenience, validated through 100+ test cycles.',
    tech: ['Arduino', 'Sensors', 'Embedded Systems', 'C++'],
    image: '/images/projects/smart-dustbin.png',
    color: '#10B981',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1GZqXq9tq4qYq9qXq9qXq9qXq9qXq9qX/view?usp=sharing',
    link: '#'
  },
  {
    id: 'autonomous-rover',
    title: 'Autonomous Rover',
    category: 'Robotics',
    metric: 'Arduino Bot',
    description: 'Autonomous moving bot using Arduino Duemilanove and obstacle avoidance sensors.',
    longDescription: 'Autonoumus Moving Bot using Arduino Duemilanove and various sensors. Designed to navigate environments autonomously by detecting and avoiding obstacles in real-time.',
    tech: ['Arduino', 'Robotics', 'Sensors', 'C++'],
    image: '/images/projects/autonomous-rover.png',
    color: '#F43F5E',
    featured: false,
    year: '2023',
    documentation: 'https://drive.google.com/file/d/1GZqXq9tq4qYq9qXq9qXq9qXq9qXq9qX/view?usp=sharing',
    link: '#'
  }
];
